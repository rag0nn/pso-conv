{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8d2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input_size = (80,60,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae619d",
   "metadata": {},
   "source": [
    "### Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac52bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893030e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Asus\\\\Desktop\\\\RAPOR Ã–DEV'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71074b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archive.zip',\n",
       " 'HAM10000_images',\n",
       " 'HAM10000_metadata.csv',\n",
       " 'hmnist_28_28_L.csv',\n",
       " 'hmnist_28_28_RGB.csv',\n",
       " 'hmnist_8_8_L.csv',\n",
       " 'hmnist_8_8_RGB.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dfed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"./dataset/HAM10000_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f32737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6710,)\n",
      "(3305,)\n",
      "10015 10015\n",
      "(6710,)\n",
      "(3305,)\n"
     ]
    }
   ],
   "source": [
    "categories = metadata[\"dx\"]\n",
    "img_names = metadata[\"image_id\"]\n",
    "categories = np.array(categories)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(img_names, categories, test_size=0.33, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape[0] + X_test.shape[0], len(img_names))\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031a32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]]\n",
      "[[0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_train_y = encoder.fit_transform(np.reshape(y_train,newshape=(-1,1))).toarray()\n",
    "encoded_test_y = encoder.fit_transform(np.reshape(y_test,newshape=(-1,1))).toarray()\n",
    "print(encoded_train_y[0:4])\n",
    "print(encoded_test_y[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d097234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6710\n",
      "3305\n"
     ]
    }
   ],
   "source": [
    "train_images =  []\n",
    "for im_name in X_train:\n",
    "    im = cv2.imread(f\"./dataset/HAM10000_images/{im_name}.jpg\")\n",
    "    im = cv2.resize(im,dsize=(image_input_size[1],image_input_size[0]))\n",
    "    train_images.append(im)\n",
    "\n",
    "test_images =  []\n",
    "for im_name in X_test:\n",
    "    im = cv2.imread(f\"./dataset/HAM10000_images/{im_name}.jpg\")\n",
    "    im = cv2.resize(im,dsize=(image_input_size[1],image_input_size[0]))\n",
    "    test_images.append(im)\n",
    "    \n",
    "print(len(train_images))\n",
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e95bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6710, 80, 60, 3) (3305, 80, 60, 3) (10015,)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "test_images = np.array(test_images)\n",
    "categories = np.array(categories)\n",
    "print(train_images.shape,test_images.shape,categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3407e3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[5000])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507908f",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e2fe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout,Input,Conv2D,MaxPooling2D,Flatten\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92772761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "excel_file_path = './results/result_history.xlsx'\n",
    "txt_file_path = \"./results/result_history.txt\"\n",
    "data = {\n",
    "    \"version\": [],\n",
    "    \"epochs\" : [],\n",
    "    \"c1\": [],\n",
    "    \"c2\": [],\n",
    "    \"c3\": [],\n",
    "    \"test_acc\": [],\n",
    "    \"train_acc\" : [],\n",
    "    \"f1_score\" : [],\n",
    "    \"test_loss\": [],\n",
    "    \"train_loss\": []\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa69b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "\n",
    "def build_and_fit_model(model_version,c1,c2,c3):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=image_input_size))\n",
    "    model.add(Conv2D(c1,kernel_size=(3,3),activation=\"relu\", kernel_initializer=tf.keras.initializers.Constant(value=0.1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(c2,kernel_size=(3,3),activation=\"relu\", kernel_initializer=tf.keras.initializers.Constant(value=0.1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(c3,kernel_size=(3,3),activation=\"relu\", kernel_initializer=tf.keras.initializers.Constant(value=0.1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7, kernel_initializer='glorot_uniform',activation=\"softmax\"))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    history = model.fit(x=train_images,y=encoded_train_y,epochs=epochs)\n",
    "    model.save(f\"./results/models/model_{model_version}.h5\")\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_images, encoded_test_y, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc , '\\nTest loss:', test_loss)\n",
    "    \n",
    "    #f1 skoru\n",
    "    predictions = model.predict(test_images)\n",
    "    binary_predictions = tf.argmax(predictions, axis=1).numpy()\n",
    "    true_labels = tf.argmax(encoded_test_y, axis=1).numpy()\n",
    "    f1 = f1_score(true_labels, binary_predictions, average='weighted')\n",
    "    print(\"AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru:\", f1)\n",
    "    \n",
    "    ##txt log\n",
    "    with open(txt_file_path,\"a\") as file:\n",
    "        file.write(f\"\\n{model_version},{int(c1)},{int(c2)},{int(c3)},{test_acc},{test_loss}\")\n",
    "        file.close()\n",
    "    \n",
    "    ##dictionery log for excel\n",
    "    data[\"version\"].append(model_version)\n",
    "    data[\"epochs\"].append(epochs)\n",
    "    data[\"c1\"].append(int(c1))\n",
    "    data[\"c2\"].append(int(c2))\n",
    "    data[\"c3\"].append(int(c3))\n",
    "    data[\"test_acc\"].append(test_acc)\n",
    "    data[\"test_loss\"].append(test_loss)\n",
    "    data[\"f1_score\"].append(f1)\n",
    "    data[\"train_acc\"].append(history.history[\"accuracy\"][-1])\n",
    "    data[\"train_loss\"].append(history.history[\"loss\"][-1])\n",
    "        \n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609890bb",
   "metadata": {},
   "source": [
    "### ParÃ§acÄ±k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f17fcd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51621c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pso_epochs = 10\n",
    "class particle:\n",
    "    def __init__(self,x,v,c1,c2):\n",
    "        self.x = x\n",
    "        self.v = v\n",
    "        self.pbest = self.x\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "    def calculate_speed(self,gbest):\n",
    "        self.v = self.v  +  self.c1 * random.uniform(0,3) * (self.pbest - self.x)  +  self.c2 *random.uniform(0,3) * (gbest - self.x)\n",
    "        print(f\"{self} par deÄŸiÅŸim hÄ±zÄ± : {self.v}\")\n",
    "        \n",
    "    def calculate_new_x(self):\n",
    "        self.x = self.x + self.v\n",
    "        if(abs(self.x) < abs(self.pbest)):\n",
    "            self.pbest = self.x\n",
    "        print(f\"{self} par x : {self.x} \")\n",
    "        print(f\"{self} par pbest : {self.pbest}\")\n",
    "\n",
    "    def calculate(self,gbest):\n",
    "        self.calculate_speed(gbest)\n",
    "        self.calculate_new_x()\n",
    "\n",
    "class Particles:\n",
    "    def __init__(self):\n",
    "        self.gbest = 1000\n",
    "        \n",
    "        self.c1 = 0.7\n",
    "        self.c2 = 0.2\n",
    "        \n",
    "    def define_particles(self,particles_init_p_list):\n",
    "        particles = []\n",
    "        for i in range(len(particles_init_p_list)):\n",
    "            particles.append(particle(particles_init_p_list[i],0,self.c1,self.c2))\n",
    "        self.particles = particles \n",
    "    \n",
    "    def find_gbest(self):\n",
    "        for particle in self.particles:\n",
    "            if(abs(particle.x) < abs(self.gbest)):\n",
    "                self.gbest = particle.x\n",
    "    \n",
    "    def epoch(self,epoch_count):\n",
    "        self.check_particle_relevance(epoch_count)\n",
    "        for particle in self.particles:\n",
    "            print(f\"--old par {particle} x : {particle.x} \")\n",
    "            particle.calculate(self.gbest)\n",
    "            print(f\"--new par {particle} x : {particle.x} \\n\")\n",
    "        self.find_gbest()\n",
    "    \n",
    "    def check_particle_relevance(self,epoch_count):\n",
    "        acc,loss = build_and_fit_model(epoch_count,abs(self.particles[0].x),abs(self.particles[1].x),abs(self.particles[2].x))\n",
    "                    \n",
    "    def fit(self):\n",
    "        epoch_counter = 0\n",
    "        while True:\n",
    "            if(epoch_counter == pso_epochs):\n",
    "                self.show_particles_x()\n",
    "                break\n",
    "            else:\n",
    "                print(f\"gbest: {self.gbest}\")\n",
    "                #time.sleep(0.1)\n",
    "                epoch_counter+=1\n",
    "                print(f\"epoch : {epoch_counter}\")\n",
    "                self.epoch(epoch_counter)\n",
    "                \n",
    "    def show_particles_x(self):\n",
    "        i = 0\n",
    "        for particle in self.particles:\n",
    "            print(f\"index:{i} {particle.x}\")\n",
    "            i+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f45ad",
   "metadata": {},
   "source": [
    "### EÄŸitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b14021b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbest: 56\n",
      "epoch : 1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 78, 58, 72)        2016      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 39, 29, 72)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 37, 27, 56)        36344     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 13, 56)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 11, 64)        32320     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 17927     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,607\n",
      "Trainable params: 88,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 7s 13ms/step - loss: 488263.1250 - accuracy: 0.4855\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 34358.6484 - accuracy: 0.5016\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 8331.5781 - accuracy: 0.5028\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2788.5193 - accuracy: 0.5051\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1281.8855 - accuracy: 0.5073\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 680.1472 - accuracy: 0.5156\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 346.8419 - accuracy: 0.5182\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 209.1320 - accuracy: 0.5174\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 116.6941 - accuracy: 0.5143\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 70.3214 - accuracy: 0.5231\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 40.2276 - accuracy: 0.5256\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 21.2545 - accuracy: 0.5250\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 9.9570 - accuracy: 0.5399\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 6.4502 - accuracy: 0.5440\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 5.5178 - accuracy: 0.5520\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 4.8315 - accuracy: 0.5526\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 4.1515 - accuracy: 0.5548\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 3.5027 - accuracy: 0.5599\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 3.0042 - accuracy: 0.5683\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.5256 - accuracy: 0.5782\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.1368 - accuracy: 0.5891\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.8253 - accuracy: 0.6045\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.5930 - accuracy: 0.6198\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.4235 - accuracy: 0.6331\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.2986 - accuracy: 0.6431\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.2151 - accuracy: 0.6517\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 4s 19ms/step - loss: 1.1589 - accuracy: 0.6593\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 4s 18ms/step - loss: 1.1188 - accuracy: 0.6641\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0940 - accuracy: 0.6660\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0777 - accuracy: 0.6662\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0662 - accuracy: 0.6666\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0586 - accuracy: 0.6687\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0554 - accuracy: 0.6697\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0506 - accuracy: 0.6697\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0487 - accuracy: 0.6694\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0467 - accuracy: 0.6697\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0434 - accuracy: 0.6690\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0430 - accuracy: 0.6697\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0403 - accuracy: 0.6705\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0419 - accuracy: 0.6696\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0393 - accuracy: 0.6689\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0390 - accuracy: 0.6686\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0377 - accuracy: 0.6706\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0363 - accuracy: 0.6683\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0352 - accuracy: 0.6687\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0331 - accuracy: 0.6693\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0355 - accuracy: 0.6675\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0307 - accuracy: 0.6675\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0321 - accuracy: 0.6666\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0258 - accuracy: 0.6696\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0261 - accuracy: 0.6683\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0279 - accuracy: 0.6696\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0261 - accuracy: 0.6699\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0306 - accuracy: 0.6724\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0299 - accuracy: 0.6723\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0290 - accuracy: 0.6720\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0255 - accuracy: 0.6694\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0247 - accuracy: 0.6720\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0336 - accuracy: 0.6717\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0239 - accuracy: 0.6700\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0290 - accuracy: 0.6718\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0202 - accuracy: 0.6721\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0208 - accuracy: 0.6723\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0232 - accuracy: 0.6735\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0132 - accuracy: 0.6754\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0242 - accuracy: 0.6747\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0190 - accuracy: 0.6745\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0142 - accuracy: 0.6741\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0087 - accuracy: 0.6748\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0174 - accuracy: 0.6750\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0031 - accuracy: 0.6760\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0079 - accuracy: 0.6760\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9929 - accuracy: 0.6747\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9734 - accuracy: 0.6754\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9338 - accuracy: 0.6800\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9218 - accuracy: 0.6809\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9307 - accuracy: 0.6797\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9158 - accuracy: 0.6836\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9139 - accuracy: 0.6811\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9151 - accuracy: 0.6785\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8953 - accuracy: 0.6836\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8913 - accuracy: 0.6851\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8768 - accuracy: 0.6845\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8812 - accuracy: 0.6839\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8744 - accuracy: 0.6841\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8726 - accuracy: 0.6905\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8617 - accuracy: 0.6954\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8646 - accuracy: 0.6939\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8666 - accuracy: 0.6887\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8616 - accuracy: 0.6949\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8392 - accuracy: 0.6994\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8471 - accuracy: 0.6970\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8305 - accuracy: 0.7022\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8290 - accuracy: 0.7052\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8204 - accuracy: 0.7037\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8178 - accuracy: 0.7054\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8146 - accuracy: 0.7054\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8034 - accuracy: 0.7104\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8035 - accuracy: 0.7083\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7859 - accuracy: 0.7134\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7922 - accuracy: 0.7156\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7794 - accuracy: 0.7212\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7760 - accuracy: 0.7210\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7567 - accuracy: 0.7255\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7571 - accuracy: 0.7219\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7520 - accuracy: 0.7262\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7627 - accuracy: 0.7215\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7451 - accuracy: 0.7292\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7305 - accuracy: 0.7343\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7407 - accuracy: 0.7297\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7226 - accuracy: 0.7320\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7206 - accuracy: 0.7410\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7222 - accuracy: 0.7377\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7083 - accuracy: 0.7435\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6835 - accuracy: 0.7548\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6833 - accuracy: 0.7517\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6711 - accuracy: 0.7525\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6787 - accuracy: 0.7554\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6550 - accuracy: 0.7544\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6424 - accuracy: 0.7651\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6476 - accuracy: 0.7638\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6278 - accuracy: 0.7745\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6239 - accuracy: 0.7694\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6168 - accuracy: 0.7760\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.5925 - accuracy: 0.7820\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5842 - accuracy: 0.7912\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5705 - accuracy: 0.7930\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5601 - accuracy: 0.7954\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5356 - accuracy: 0.8018\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5370 - accuracy: 0.8069\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4975 - accuracy: 0.8192\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5240 - accuracy: 0.8091\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4728 - accuracy: 0.8271\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.4681 - accuracy: 0.8313\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.4346 - accuracy: 0.8373\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.4291 - accuracy: 0.8419\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4077 - accuracy: 0.8566\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3843 - accuracy: 0.8602\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3597 - accuracy: 0.8669\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3380 - accuracy: 0.8727\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3164 - accuracy: 0.8848\n",
      "Epoch 142/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3037 - accuracy: 0.8937\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3062 - accuracy: 0.8864\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3091 - accuracy: 0.8869\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.2586 - accuracy: 0.9088\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.2438 - accuracy: 0.9125\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.2218 - accuracy: 0.9204\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.2278 - accuracy: 0.9198\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.2215 - accuracy: 0.9188\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.1866 - accuracy: 0.9298\n",
      "104/104 - 1s - loss: 1.6406 - accuracy: 0.6841 - 662ms/epoch - 6ms/step\n",
      "\n",
      "Test accuracy: 0.6841149926185608 \n",
      "Test loss: 1.6405595541000366\n",
      "104/104 [==============================] - 1s 4ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6731218089312309\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 72 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -1.1590405053458743\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 70.84095949465413 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 70.84095949465413\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 70.84095949465413 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 56 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : 0.0\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 56\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 64 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -0.13918253084513826\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 63.86081746915486 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 63.86081746915486\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 63.86081746915486 \n",
      "\n",
      "gbest: 56\n",
      "epoch : 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 78, 58, 70)        1960      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 39, 29, 70)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 37, 27, 56)        35336     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 18, 13, 56)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 11, 63)        31815     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 5, 63)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2520)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 17647     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,758\n",
      "Trainable params: 86,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 407757.6875 - accuracy: 0.4945\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 18078.7012 - accuracy: 0.4943\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 4855.0249 - accuracy: 0.5095\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1795.4818 - accuracy: 0.5122\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 951.5318 - accuracy: 0.5125\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 447.5036 - accuracy: 0.5218\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 202.9579 - accuracy: 0.5228\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 109.8495 - accuracy: 0.5286\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 52.4298 - accuracy: 0.5349\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 23.1264 - accuracy: 0.5395\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 14.3003 - accuracy: 0.5380\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 12.1577 - accuracy: 0.5393\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 10.1854 - accuracy: 0.5385\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 8.3756 - accuracy: 0.5337\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 6.7748 - accuracy: 0.5452\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 5.3583 - accuracy: 0.5428\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 4.2422 - accuracy: 0.5484\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 3.3597 - accuracy: 0.5621\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.6620 - accuracy: 0.5675\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 2.0875 - accuracy: 0.5860\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.7060 - accuracy: 0.5966\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.4305 - accuracy: 0.6186\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.2538 - accuracy: 0.6370\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.1543 - accuracy: 0.6480\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.1011 - accuracy: 0.6599\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0751 - accuracy: 0.6638\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0627 - accuracy: 0.6660\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0558 - accuracy: 0.6663\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0532 - accuracy: 0.6669\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0503 - accuracy: 0.6668\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0476 - accuracy: 0.6689\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0457 - accuracy: 0.6686\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0466 - accuracy: 0.6681\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0434 - accuracy: 0.6668\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0436 - accuracy: 0.6681\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0423 - accuracy: 0.6675\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0434 - accuracy: 0.6690\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0421 - accuracy: 0.6663\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0456 - accuracy: 0.6659\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 1.0416 - accuracy: 0.6669\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 1.0394 - accuracy: 0.6668\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0382 - accuracy: 0.6659\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0424 - accuracy: 0.6668\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 1.0401 - accuracy: 0.6671\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0351 - accuracy: 0.6696\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0393 - accuracy: 0.6681\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0360 - accuracy: 0.6677\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0306 - accuracy: 0.6683\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0250 - accuracy: 0.6671\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0310 - accuracy: 0.6657\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0282 - accuracy: 0.6671\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0244 - accuracy: 0.6657\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0267 - accuracy: 0.6644\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0264 - accuracy: 0.6665\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0259 - accuracy: 0.6677\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0231 - accuracy: 0.6694\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0254 - accuracy: 0.6668\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0296 - accuracy: 0.6668\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0221 - accuracy: 0.6724\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0289 - accuracy: 0.6694\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0186 - accuracy: 0.6717\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0203 - accuracy: 0.6717\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0169 - accuracy: 0.6730\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0265 - accuracy: 0.6721\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0234 - accuracy: 0.6735\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0083 - accuracy: 0.6744\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9968 - accuracy: 0.6720\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9776 - accuracy: 0.6738\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9666 - accuracy: 0.6775\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9491 - accuracy: 0.6765\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9521 - accuracy: 0.6762\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9393 - accuracy: 0.6768\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9312 - accuracy: 0.6757\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9259 - accuracy: 0.6770\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9114 - accuracy: 0.6806\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9256 - accuracy: 0.6760\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9010 - accuracy: 0.6820\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9023 - accuracy: 0.6817\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9010 - accuracy: 0.6791\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8960 - accuracy: 0.6830\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8914 - accuracy: 0.6820\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8912 - accuracy: 0.6830\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8855 - accuracy: 0.6861\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8746 - accuracy: 0.6884\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8854 - accuracy: 0.6833\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8738 - accuracy: 0.6870\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8753 - accuracy: 0.6878\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8683 - accuracy: 0.6881\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8664 - accuracy: 0.6881\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8618 - accuracy: 0.6927\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8666 - accuracy: 0.6911\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8541 - accuracy: 0.6920\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8548 - accuracy: 0.6927\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8510 - accuracy: 0.6952\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8560 - accuracy: 0.6945\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8469 - accuracy: 0.6957\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8533 - accuracy: 0.6948\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8366 - accuracy: 0.6964\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8377 - accuracy: 0.6973\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8357 - accuracy: 0.6976\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8370 - accuracy: 0.7004\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8291 - accuracy: 0.7019\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8370 - accuracy: 0.7013\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8187 - accuracy: 0.7072\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8062 - accuracy: 0.7104\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8072 - accuracy: 0.7076\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8089 - accuracy: 0.7063\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8120 - accuracy: 0.7049\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8032 - accuracy: 0.7122\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8044 - accuracy: 0.7124\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7968 - accuracy: 0.7133\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7905 - accuracy: 0.7185\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7857 - accuracy: 0.7167\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7789 - accuracy: 0.7139\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7754 - accuracy: 0.7182\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7572 - accuracy: 0.7267\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7585 - accuracy: 0.7267\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7479 - accuracy: 0.7295\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7446 - accuracy: 0.7271\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7500 - accuracy: 0.7308\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7326 - accuracy: 0.7303\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7301 - accuracy: 0.7306\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7164 - accuracy: 0.7386\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7003 - accuracy: 0.7468\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6881 - accuracy: 0.7531\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6659 - accuracy: 0.7584\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6599 - accuracy: 0.7584\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6620 - accuracy: 0.7572\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6542 - accuracy: 0.7618\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6273 - accuracy: 0.7674\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6041 - accuracy: 0.7773\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5933 - accuracy: 0.7829\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.5737 - accuracy: 0.7885\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5496 - accuracy: 0.7970\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5343 - accuracy: 0.8006\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5265 - accuracy: 0.8025\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4986 - accuracy: 0.8162\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.4763 - accuracy: 0.8231\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.4460 - accuracy: 0.8323\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4547 - accuracy: 0.8325\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.4255 - accuracy: 0.8440\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3893 - accuracy: 0.8559\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3729 - accuracy: 0.8630\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3744 - accuracy: 0.8610\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.3585 - accuracy: 0.8694\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3586 - accuracy: 0.8668\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.3143 - accuracy: 0.8873\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.2893 - accuracy: 0.8979\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.2940 - accuracy: 0.8897\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.2742 - accuracy: 0.9051\n",
      "104/104 - 1s - loss: 1.3088 - accuracy: 0.6962 - 642ms/epoch - 6ms/step\n",
      "\n",
      "Test accuracy: 0.6962178349494934 \n",
      "Test loss: 1.3087655305862427\n",
      "104/104 [==============================] - 0s 4ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6767499158627518\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 70.84095949465413 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -8.27774930334876\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 62.56321019130537 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 62.56321019130537\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 62.56321019130537 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : 0.0\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 56\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 63.86081746915486 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -0.41611150327349483\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 63.44470596588136 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 63.44470596588136\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 63.44470596588136 \n",
      "\n",
      "gbest: 56\n",
      "epoch : 3\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 78, 58, 62)        1736      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 39, 29, 62)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 37, 27, 56)        31304     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 18, 13, 56)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 11, 63)        31815     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 5, 63)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2520)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 17647     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,502\n",
      "Trainable params: 82,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 382218.3750 - accuracy: 0.4970\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 16663.0039 - accuracy: 0.5009\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 4565.7764 - accuracy: 0.5195\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1741.2596 - accuracy: 0.5216\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 792.8366 - accuracy: 0.5222\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 397.3686 - accuracy: 0.5264\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 204.7459 - accuracy: 0.5326\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 107.9007 - accuracy: 0.5308\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 46.2513 - accuracy: 0.5453\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 21.7022 - accuracy: 0.5449\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 15.8728 - accuracy: 0.5483\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 12.9577 - accuracy: 0.5461\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 11.1721 - accuracy: 0.5477\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 9.2451 - accuracy: 0.5493\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 7.6810 - accuracy: 0.5481\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 6.0751 - accuracy: 0.5566\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 4.8916 - accuracy: 0.5590\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 3.8765 - accuracy: 0.5642\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 3.0444 - accuracy: 0.5663\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2.4093 - accuracy: 0.5787\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.9220 - accuracy: 0.5918\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.5778 - accuracy: 0.6075\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.3415 - accuracy: 0.6306\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.1953 - accuracy: 0.6440\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.1127 - accuracy: 0.6581\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0740 - accuracy: 0.6633\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0575 - accuracy: 0.6648\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0509 - accuracy: 0.6663\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0457 - accuracy: 0.6672\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0437 - accuracy: 0.6672\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0411 - accuracy: 0.6683\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0422 - accuracy: 0.6678\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0391 - accuracy: 0.6677\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0373 - accuracy: 0.6678\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0376 - accuracy: 0.6669\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0351 - accuracy: 0.6659\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0322 - accuracy: 0.6659\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0361 - accuracy: 0.6680\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0327 - accuracy: 0.6654\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0303 - accuracy: 0.6674\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0288 - accuracy: 0.6705\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0271 - accuracy: 0.6697\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0256 - accuracy: 0.6686\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0242 - accuracy: 0.6692\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0208 - accuracy: 0.6686\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0279 - accuracy: 0.6681\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0188 - accuracy: 0.6699\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0184 - accuracy: 0.6675\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0199 - accuracy: 0.6674\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0200 - accuracy: 0.6678\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0170 - accuracy: 0.6683\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0133 - accuracy: 0.6675\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0205 - accuracy: 0.6671\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0246 - accuracy: 0.6669\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0122 - accuracy: 0.6696\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0145 - accuracy: 0.6699\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0144 - accuracy: 0.6677\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 1.0145 - accuracy: 0.6687\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0062 - accuracy: 0.6692\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0082 - accuracy: 0.6699\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0108 - accuracy: 0.6697\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0053 - accuracy: 0.6711\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0162 - accuracy: 0.6694\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 1.0122 - accuracy: 0.6729\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0093 - accuracy: 0.6729\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0029 - accuracy: 0.6732\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0038 - accuracy: 0.6733\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0019 - accuracy: 0.6735\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0068 - accuracy: 0.6756\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0124 - accuracy: 0.6741\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0045 - accuracy: 0.6759\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9978 - accuracy: 0.6753\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0037 - accuracy: 0.6762\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 1.0029 - accuracy: 0.6748\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 1.0014 - accuracy: 0.6745\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9940 - accuracy: 0.6768\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0172 - accuracy: 0.6739\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0118 - accuracy: 0.6756\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 1.0049 - accuracy: 0.6759\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9939 - accuracy: 0.6768\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9966 - accuracy: 0.6766\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.9891 - accuracy: 0.6762\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9924 - accuracy: 0.6768\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9880 - accuracy: 0.6773\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9923 - accuracy: 0.6772\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9722 - accuracy: 0.6773\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9762 - accuracy: 0.6778\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9732 - accuracy: 0.6788\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9764 - accuracy: 0.6778\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9718 - accuracy: 0.6782\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9810 - accuracy: 0.6791\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9644 - accuracy: 0.6799\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9586 - accuracy: 0.6787\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9677 - accuracy: 0.6823\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9553 - accuracy: 0.6779\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9562 - accuracy: 0.6796\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.9528 - accuracy: 0.6811\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9525 - accuracy: 0.6827\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9470 - accuracy: 0.6812\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9539 - accuracy: 0.6806\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9454 - accuracy: 0.6832\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9427 - accuracy: 0.6852\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9489 - accuracy: 0.6832\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9333 - accuracy: 0.6857\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9364 - accuracy: 0.6854\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9347 - accuracy: 0.6854\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.9184 - accuracy: 0.6852\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9225 - accuracy: 0.6841\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9098 - accuracy: 0.6902\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.9057 - accuracy: 0.6872\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.9015 - accuracy: 0.6893\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.8873 - accuracy: 0.6934\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8799 - accuracy: 0.6973\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.8690 - accuracy: 0.6975\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8698 - accuracy: 0.6957\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8636 - accuracy: 0.6979\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8598 - accuracy: 0.7003\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8598 - accuracy: 0.7003\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.8628 - accuracy: 0.6984\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8410 - accuracy: 0.7057\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8405 - accuracy: 0.7019\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8414 - accuracy: 0.7077\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.8273 - accuracy: 0.7067\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.8261 - accuracy: 0.7104\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.8286 - accuracy: 0.7042\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.8122 - accuracy: 0.7162\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.8008 - accuracy: 0.7168\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7949 - accuracy: 0.7155\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7902 - accuracy: 0.7204\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.7795 - accuracy: 0.7243\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.7658 - accuracy: 0.7258\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.7556 - accuracy: 0.7325\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.7588 - accuracy: 0.7331\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.7384 - accuracy: 0.7376\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7396 - accuracy: 0.7434\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7185 - accuracy: 0.7432\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.7112 - accuracy: 0.7510\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.7094 - accuracy: 0.7486\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6891 - accuracy: 0.7550\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.6862 - accuracy: 0.7565\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 3s 13ms/step - loss: 0.6603 - accuracy: 0.7648\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6526 - accuracy: 0.7678\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 3s 14ms/step - loss: 0.6419 - accuracy: 0.7705\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 4s 17ms/step - loss: 0.6110 - accuracy: 0.7809\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 0.6162 - accuracy: 0.7806\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5973 - accuracy: 0.7836\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.5827 - accuracy: 0.7885\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.5502 - accuracy: 0.8034\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.5359 - accuracy: 0.8040\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 0.5361 - accuracy: 0.8104\n",
      "104/104 - 1s - loss: 1.0716 - accuracy: 0.6741 - 675ms/epoch - 6ms/step\n",
      "\n",
      "Test accuracy: 0.6741300821304321 \n",
      "Test loss: 1.0716170072555542\n",
      "104/104 [==============================] - 0s 4ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6238230461220892\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 62.56321019130537 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 50.588867746539805 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 50.588867746539805\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 50.588867746539805 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : 0.0\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 56\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 63.44470596588136 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -1.0986276156507178\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 62.34607835023064 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 62.34607835023064\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 62.34607835023064 \n",
      "\n",
      "gbest: 50.588867746539805\n",
      "epoch : 4\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 78, 58, 50)        1400      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 39, 29, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 37, 27, 56)        25256     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 18, 13, 56)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 11, 62)        31310     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 8, 5, 62)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2480)              0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 17367     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75,333\n",
      "Trainable params: 75,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 360629.5625 - accuracy: 0.4990\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 3s 12ms/step - loss: 19126.8379 - accuracy: 0.5101\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 5658.1494 - accuracy: 0.5136\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 2s 12ms/step - loss: 2421.4331 - accuracy: 0.5155\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 957.9266 - accuracy: 0.5292\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 462.7247 - accuracy: 0.5235\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 297.2881 - accuracy: 0.5252\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 170.5163 - accuracy: 0.5337\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 86.6506 - accuracy: 0.5331\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 50.0248 - accuracy: 0.5349\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 25.8480 - accuracy: 0.5416\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 12.0609 - accuracy: 0.5535\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 8.0173 - accuracy: 0.5513\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 6.6697 - accuracy: 0.5571\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 5.7003 - accuracy: 0.5587\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 4.8501 - accuracy: 0.5618\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 4.1091 - accuracy: 0.5645\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 3.5077 - accuracy: 0.5666\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 2.9037 - accuracy: 0.5782\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 2.3891 - accuracy: 0.5844\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 2.0043 - accuracy: 0.5963\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.6909 - accuracy: 0.6079\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.4841 - accuracy: 0.6203\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.3170 - accuracy: 0.6356\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.2091 - accuracy: 0.6441\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.1374 - accuracy: 0.6534\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0944 - accuracy: 0.6590\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0669 - accuracy: 0.6630\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0525 - accuracy: 0.6663\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0442 - accuracy: 0.6675\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0379 - accuracy: 0.6699\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0339 - accuracy: 0.6699\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0333 - accuracy: 0.6681\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0298 - accuracy: 0.6674\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0287 - accuracy: 0.6689\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0279 - accuracy: 0.6677\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0269 - accuracy: 0.6683\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0245 - accuracy: 0.6683\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0211 - accuracy: 0.6672\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0221 - accuracy: 0.6669\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0230 - accuracy: 0.6659\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0203 - accuracy: 0.6665\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0206 - accuracy: 0.6659\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0145 - accuracy: 0.6674\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0181 - accuracy: 0.6641\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0152 - accuracy: 0.6686\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0118 - accuracy: 0.6668\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0134 - accuracy: 0.6633\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0091 - accuracy: 0.6653\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0120 - accuracy: 0.6663\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0118 - accuracy: 0.6653\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0072 - accuracy: 0.6681\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0014 - accuracy: 0.6703\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0017 - accuracy: 0.6726\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0048 - accuracy: 0.6706\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0024 - accuracy: 0.6700\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9946 - accuracy: 0.6718\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9987 - accuracy: 0.6724\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9957 - accuracy: 0.6741\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0063 - accuracy: 0.6720\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0082 - accuracy: 0.6702\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0013 - accuracy: 0.6762\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9986 - accuracy: 0.6729\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0029 - accuracy: 0.6748\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0004 - accuracy: 0.6742\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0117 - accuracy: 0.6745\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9992 - accuracy: 0.6759\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9914 - accuracy: 0.6759\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9946 - accuracy: 0.6757\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9968 - accuracy: 0.6735\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0094 - accuracy: 0.6748\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0005 - accuracy: 0.6772\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 1.0031 - accuracy: 0.6753\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9707 - accuracy: 0.6782\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9725 - accuracy: 0.6753\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9236 - accuracy: 0.6814\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.9404 - accuracy: 0.6756\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9118 - accuracy: 0.6827\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9319 - accuracy: 0.6811\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9090 - accuracy: 0.6809\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9096 - accuracy: 0.6823\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9091 - accuracy: 0.6818\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8931 - accuracy: 0.6833\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8858 - accuracy: 0.6860\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8852 - accuracy: 0.6845\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8972 - accuracy: 0.6864\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8802 - accuracy: 0.6842\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8662 - accuracy: 0.6872\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8570 - accuracy: 0.6903\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8548 - accuracy: 0.6951\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8644 - accuracy: 0.6860\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8537 - accuracy: 0.6928\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8518 - accuracy: 0.6961\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8528 - accuracy: 0.6909\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8523 - accuracy: 0.6940\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8378 - accuracy: 0.6970\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8307 - accuracy: 0.6991\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8235 - accuracy: 0.6993\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8265 - accuracy: 0.7006\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8224 - accuracy: 0.7003\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8131 - accuracy: 0.7048\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8256 - accuracy: 0.7006\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8045 - accuracy: 0.7083\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8060 - accuracy: 0.7139\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8035 - accuracy: 0.7072\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7961 - accuracy: 0.7095\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.8066 - accuracy: 0.7073\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7943 - accuracy: 0.7107\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7871 - accuracy: 0.7173\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7770 - accuracy: 0.7171\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7892 - accuracy: 0.7121\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 2s 11ms/step - loss: 0.7698 - accuracy: 0.7189\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7746 - accuracy: 0.7173\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7647 - accuracy: 0.7213\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7594 - accuracy: 0.7189\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7395 - accuracy: 0.7286\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7317 - accuracy: 0.7326\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7391 - accuracy: 0.7285\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7154 - accuracy: 0.7376\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7153 - accuracy: 0.7382\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7105 - accuracy: 0.7417\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6909 - accuracy: 0.7483\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7023 - accuracy: 0.7428\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6737 - accuracy: 0.7487\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6780 - accuracy: 0.7539\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6684 - accuracy: 0.7539\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6605 - accuracy: 0.7575\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6471 - accuracy: 0.7590\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6333 - accuracy: 0.7672\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.6116 - accuracy: 0.7750\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5934 - accuracy: 0.7806\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5789 - accuracy: 0.7861\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5611 - accuracy: 0.7940\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5527 - accuracy: 0.7930\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5237 - accuracy: 0.8085\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5056 - accuracy: 0.8168\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4953 - accuracy: 0.8206\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4768 - accuracy: 0.8258\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4466 - accuracy: 0.8322\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4452 - accuracy: 0.8316\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4198 - accuracy: 0.8429\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.4301 - accuracy: 0.8387\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3922 - accuracy: 0.8557\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3832 - accuracy: 0.8569\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3578 - accuracy: 0.8696\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3404 - accuracy: 0.8763\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3237 - accuracy: 0.8829\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3088 - accuracy: 0.8873\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3006 - accuracy: 0.8878\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.3199 - accuracy: 0.8803\n",
      "104/104 - 1s - loss: 1.4724 - accuracy: 0.6823 - 539ms/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.6822995543479919 \n",
      "Test loss: 1.4723668098449707\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6426665077488646\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 50.588867746539805 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 38.614525301774236 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 38.614525301774236\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 38.614525301774236 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 56.0 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -0.752524779793995\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 55.247475220206006 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 55.247475220206006\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 55.247475220206006 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 62.34607835023064 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -2.8879879147199308\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 59.45809043551071 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 59.45809043551071\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 59.45809043551071 \n",
      "\n",
      "gbest: 38.614525301774236\n",
      "epoch : 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 78, 58, 38)        1064      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 39, 29, 38)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 37, 27, 55)        18865     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 18, 13, 55)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 16, 11, 59)        29264     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 8, 5, 59)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2360)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 16527     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,720\n",
      "Trainable params: 65,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 193190.1875 - accuracy: 0.4934\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 11567.6943 - accuracy: 0.5077\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2768.3335 - accuracy: 0.5003\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 739.3135 - accuracy: 0.5122\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 341.6825 - accuracy: 0.5103\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 172.4918 - accuracy: 0.5091\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 91.6668 - accuracy: 0.5133\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 40.9809 - accuracy: 0.5252\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 18.4952 - accuracy: 0.5295\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 8.2746 - accuracy: 0.5434\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 6.3178 - accuracy: 0.5438\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 5.3942 - accuracy: 0.5469\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 4.4764 - accuracy: 0.5547\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 3.6872 - accuracy: 0.5602\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 3.0033 - accuracy: 0.5747\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.4528 - accuracy: 0.5805\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 2.0421 - accuracy: 0.5934\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.7224 - accuracy: 0.6097\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.4954 - accuracy: 0.6224\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.3353 - accuracy: 0.6370\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.2212 - accuracy: 0.6489\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.1525 - accuracy: 0.6590\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.1094 - accuracy: 0.6654\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0821 - accuracy: 0.6690\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0671 - accuracy: 0.6693\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0576 - accuracy: 0.6693\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0526 - accuracy: 0.6693\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0493 - accuracy: 0.6703\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0463 - accuracy: 0.6706\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0444 - accuracy: 0.6699\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0427 - accuracy: 0.6692\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0439 - accuracy: 0.6671\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0418 - accuracy: 0.6687\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0392 - accuracy: 0.6694\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0397 - accuracy: 0.6686\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0365 - accuracy: 0.6684\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0366 - accuracy: 0.6684\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0354 - accuracy: 0.6681\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0362 - accuracy: 0.6674\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0374 - accuracy: 0.6699\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0331 - accuracy: 0.6683\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0345 - accuracy: 0.6668\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0317 - accuracy: 0.6706\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0342 - accuracy: 0.6687\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0282 - accuracy: 0.6700\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0296 - accuracy: 0.6699\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0286 - accuracy: 0.6681\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0295 - accuracy: 0.6684\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0366 - accuracy: 0.6666\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0353 - accuracy: 0.6714\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0262 - accuracy: 0.6727\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0197 - accuracy: 0.6718\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0170 - accuracy: 0.6742\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0244 - accuracy: 0.6717\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0240 - accuracy: 0.6718\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0158 - accuracy: 0.6727\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0116 - accuracy: 0.6732\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0233 - accuracy: 0.6703\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0246 - accuracy: 0.6721\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0115 - accuracy: 0.6751\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0155 - accuracy: 0.6745\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0183 - accuracy: 0.6763\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0127 - accuracy: 0.6757\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0064 - accuracy: 0.6757\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0136 - accuracy: 0.6747\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0044 - accuracy: 0.6768\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.9999 - accuracy: 0.6765\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0092 - accuracy: 0.6775\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0012 - accuracy: 0.6765\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9961 - accuracy: 0.6776\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0057 - accuracy: 0.6782\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0124 - accuracy: 0.6744\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0083 - accuracy: 0.6760\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0014 - accuracy: 0.6768\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 1.0006 - accuracy: 0.6788\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9899 - accuracy: 0.6791\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9984 - accuracy: 0.6763\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9976 - accuracy: 0.6756\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9788 - accuracy: 0.6787\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9738 - accuracy: 0.6790\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9766 - accuracy: 0.6785\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9809 - accuracy: 0.6763\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9725 - accuracy: 0.6788\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9719 - accuracy: 0.6791\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9632 - accuracy: 0.6791\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9613 - accuracy: 0.6770\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9608 - accuracy: 0.6788\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9612 - accuracy: 0.6773\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9519 - accuracy: 0.6814\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9596 - accuracy: 0.6772\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9462 - accuracy: 0.6818\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9370 - accuracy: 0.6817\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9378 - accuracy: 0.6820\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9314 - accuracy: 0.6849\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9353 - accuracy: 0.6824\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9206 - accuracy: 0.6818\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9215 - accuracy: 0.6814\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9117 - accuracy: 0.6875\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9072 - accuracy: 0.6881\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.9005 - accuracy: 0.6908\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8969 - accuracy: 0.6943\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8939 - accuracy: 0.6946\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8638 - accuracy: 0.6930\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8582 - accuracy: 0.6966\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8565 - accuracy: 0.6966\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8436 - accuracy: 0.6979\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8317 - accuracy: 0.7040\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8387 - accuracy: 0.7016\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8285 - accuracy: 0.7067\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8199 - accuracy: 0.7119\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8017 - accuracy: 0.7134\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7984 - accuracy: 0.7155\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7869 - accuracy: 0.7158\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7924 - accuracy: 0.7182\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.7755 - accuracy: 0.7231\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7634 - accuracy: 0.7280\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7622 - accuracy: 0.7261\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7499 - accuracy: 0.7292\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7320 - accuracy: 0.7370\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7286 - accuracy: 0.7358\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.8031 - accuracy: 0.7235\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.7067 - accuracy: 0.7492\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6972 - accuracy: 0.7514\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6970 - accuracy: 0.7517\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6789 - accuracy: 0.7554\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6635 - accuracy: 0.7581\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6594 - accuracy: 0.7613\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6492 - accuracy: 0.7663\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6387 - accuracy: 0.7736\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.6236 - accuracy: 0.7784\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5960 - accuracy: 0.7832\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5971 - accuracy: 0.7838\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5878 - accuracy: 0.7882\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5671 - accuracy: 0.8022\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5496 - accuracy: 0.8024\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5263 - accuracy: 0.8104\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 2s 10ms/step - loss: 0.5109 - accuracy: 0.8128\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4962 - accuracy: 0.8230\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4939 - accuracy: 0.8235\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4568 - accuracy: 0.8404\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4786 - accuracy: 0.8238\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4356 - accuracy: 0.8420\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4329 - accuracy: 0.8428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4155 - accuracy: 0.8493\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3817 - accuracy: 0.8636\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3873 - accuracy: 0.8624\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3817 - accuracy: 0.8630\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3618 - accuracy: 0.8720\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 507s 2s/step - loss: 0.3608 - accuracy: 0.8669\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.3262 - accuracy: 0.8855\n",
      "104/104 - 1s - loss: 1.3666 - accuracy: 0.6563 - 504ms/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.6562783718109131 \n",
      "Test loss: 1.366576910018921\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6488692672636507\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 38.614525301774236 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 26.640182857008664 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 26.640182857008664\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 26.640182857008664 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 55.247475220206006 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -7.931585569681021\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 47.31588965052499 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 47.31588965052499\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 47.31588965052499 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 59.45809043551071 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -8.35269158297869\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 51.10539885253202 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 51.10539885253202\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 51.10539885253202 \n",
      "\n",
      "gbest: 26.640182857008664\n",
      "epoch : 6\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 78, 58, 26)        728       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 39, 29, 26)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 37, 27, 47)        11045     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 18, 13, 47)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 16, 11, 51)        21624     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 5, 51)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2040)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 14287     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,684\n",
      "Trainable params: 47,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 2s 8ms/step - loss: 119954.3672 - accuracy: 0.4870\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 5554.9736 - accuracy: 0.5015\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1710.3003 - accuracy: 0.5033\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 725.3577 - accuracy: 0.4994\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 310.0657 - accuracy: 0.5194\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 143.3013 - accuracy: 0.5165\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 75.1263 - accuracy: 0.5224\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 33.8074 - accuracy: 0.5165\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 14.3617 - accuracy: 0.5270\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 6.6856 - accuracy: 0.5437\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 5.2959 - accuracy: 0.5483\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 4.4584 - accuracy: 0.5496\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 3.7599 - accuracy: 0.5584\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 3.1260 - accuracy: 0.5632\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 2.6067 - accuracy: 0.5736\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 2.1783 - accuracy: 0.5833\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.8608 - accuracy: 0.5952\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.6105 - accuracy: 0.6101\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.4200 - accuracy: 0.6231\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.3016 - accuracy: 0.6376\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.2075 - accuracy: 0.6499\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.1510 - accuracy: 0.6575\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.1179 - accuracy: 0.6630\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0924 - accuracy: 0.6657\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0789 - accuracy: 0.6669\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0689 - accuracy: 0.6680\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0625 - accuracy: 0.6684\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0593 - accuracy: 0.6692\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0564 - accuracy: 0.6690\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0536 - accuracy: 0.6683\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0524 - accuracy: 0.6681\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0488 - accuracy: 0.6683\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0509 - accuracy: 0.6684\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0469 - accuracy: 0.6690\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0464 - accuracy: 0.6687\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0441 - accuracy: 0.6675\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0424 - accuracy: 0.6675\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0416 - accuracy: 0.6674\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0386 - accuracy: 0.6678\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0444 - accuracy: 0.6684\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0405 - accuracy: 0.6662\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0354 - accuracy: 0.6666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0384 - accuracy: 0.6677\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0344 - accuracy: 0.6657\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0306 - accuracy: 0.6690\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0318 - accuracy: 0.6665\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0311 - accuracy: 0.6675\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0282 - accuracy: 0.6675\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0301 - accuracy: 0.6699\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0212 - accuracy: 0.6720\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0133 - accuracy: 0.6715\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0109 - accuracy: 0.6720\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0150 - accuracy: 0.6715\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0247 - accuracy: 0.6736\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0215 - accuracy: 0.6729\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0126 - accuracy: 0.6732\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0019 - accuracy: 0.6720\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0151 - accuracy: 0.6712\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0020 - accuracy: 0.6756\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0088 - accuracy: 0.6768\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.9976 - accuracy: 0.6742\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0007 - accuracy: 0.6766\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0017 - accuracy: 0.6745\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 1.0116 - accuracy: 0.6742\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0020 - accuracy: 0.6768\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.9928 - accuracy: 0.6736\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 1.0013 - accuracy: 0.6754\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.9900 - accuracy: 0.6754\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.9671 - accuracy: 0.6762\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.9325 - accuracy: 0.6796\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.9233 - accuracy: 0.6794\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.9014 - accuracy: 0.6835\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.9022 - accuracy: 0.6841\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8901 - accuracy: 0.6787\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8816 - accuracy: 0.6881\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8807 - accuracy: 0.6881\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8711 - accuracy: 0.6894\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8595 - accuracy: 0.6915\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8587 - accuracy: 0.6912\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8620 - accuracy: 0.6921\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8519 - accuracy: 0.6946\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8536 - accuracy: 0.6933\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8443 - accuracy: 0.7012\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8573 - accuracy: 0.6936\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8483 - accuracy: 0.6978\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8357 - accuracy: 0.6979\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8266 - accuracy: 0.6997\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8619 - accuracy: 0.6928\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8371 - accuracy: 0.7000\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8270 - accuracy: 0.6993\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8306 - accuracy: 0.6987\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8151 - accuracy: 0.7051\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.8147 - accuracy: 0.7080\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7995 - accuracy: 0.7107\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.7972 - accuracy: 0.7131\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7959 - accuracy: 0.7098\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7951 - accuracy: 0.7104\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7963 - accuracy: 0.7130\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7839 - accuracy: 0.7174\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7772 - accuracy: 0.7224\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7812 - accuracy: 0.7124\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7772 - accuracy: 0.7200\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7523 - accuracy: 0.7279\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7536 - accuracy: 0.7265\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7538 - accuracy: 0.7240\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7393 - accuracy: 0.7250\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7321 - accuracy: 0.7380\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7318 - accuracy: 0.7347\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7361 - accuracy: 0.7364\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7143 - accuracy: 0.7370\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.7058 - accuracy: 0.7402\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6997 - accuracy: 0.7475\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6888 - accuracy: 0.7471\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6917 - accuracy: 0.7487\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6812 - accuracy: 0.7562\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.6642 - accuracy: 0.7590\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6633 - accuracy: 0.7545\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6435 - accuracy: 0.7587\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6263 - accuracy: 0.7721\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.6230 - accuracy: 0.7718\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6001 - accuracy: 0.7760\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5867 - accuracy: 0.7808\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5672 - accuracy: 0.7931\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5568 - accuracy: 0.7967\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.8012\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5304 - accuracy: 0.8010\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5244 - accuracy: 0.8069\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.4831 - accuracy: 0.8194\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.5053 - accuracy: 0.8133\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.4732 - accuracy: 0.8247\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.4238 - accuracy: 0.8465\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.4177 - accuracy: 0.8462\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.8495\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.3655 - accuracy: 0.8692\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.3619 - accuracy: 0.8694\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.3419 - accuracy: 0.8788\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.3235 - accuracy: 0.8836\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2999 - accuracy: 0.8923\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.3145 - accuracy: 0.8864\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2702 - accuracy: 0.9043\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2583 - accuracy: 0.9042\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2635 - accuracy: 0.9058\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2328 - accuracy: 0.9155\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2406 - accuracy: 0.9136\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2347 - accuracy: 0.9131\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.1819 - accuracy: 0.9352\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.1858 - accuracy: 0.9329\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.1770 - accuracy: 0.9390\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.2053 - accuracy: 0.9262\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.1632 - accuracy: 0.9425\n",
      "104/104 - 0s - loss: 1.9812 - accuracy: 0.6890 - 430ms/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.6889561414718628 \n",
      "Test loss: 1.9811948537826538\n",
      "104/104 [==============================] - 0s 2ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6460551461996585\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 26.640182857008664 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 14.665840412243092 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 14.665840412243092\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 14.665840412243092 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 47.31588965052499 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -9.342041073593993\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 37.97384857693099 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 37.97384857693099\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 37.97384857693099 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 51.10539885253202 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -20.293994338526588\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 30.81140451400543 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 30.81140451400543\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 30.81140451400543 \n",
      "\n",
      "gbest: 14.665840412243092\n",
      "epoch : 7\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 78, 58, 14)        392       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 39, 29, 14)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 37, 27, 37)        4699      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 18, 13, 37)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 16, 11, 30)        10020     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 8, 5, 30)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1200)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 7)                 8407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,518\n",
      "Trainable params: 23,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 2s 6ms/step - loss: 36521.5352 - accuracy: 0.4849\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1259.9580 - accuracy: 0.4996\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 418.6032 - accuracy: 0.5115\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 174.4024 - accuracy: 0.5067\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 73.7803 - accuracy: 0.5125\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 25.8939 - accuracy: 0.5106\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 9.4100 - accuracy: 0.5343\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 6.8552 - accuracy: 0.5374\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 5.6821 - accuracy: 0.5356\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 4.5215 - accuracy: 0.5438\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 3.6731 - accuracy: 0.5483\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 2.8734 - accuracy: 0.5611\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 2.3221 - accuracy: 0.5724\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.9092 - accuracy: 0.5948\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.6162 - accuracy: 0.6040\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.4035 - accuracy: 0.6267\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.2735 - accuracy: 0.6379\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.1950 - accuracy: 0.6508\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.1412 - accuracy: 0.6580\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.1107 - accuracy: 0.6627\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0917 - accuracy: 0.6669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0804 - accuracy: 0.6689\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0733 - accuracy: 0.6692\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0696 - accuracy: 0.6694\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0649 - accuracy: 0.6700\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0633 - accuracy: 0.6700\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0600 - accuracy: 0.6696\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0584 - accuracy: 0.6699\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0569 - accuracy: 0.6700\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0584 - accuracy: 0.6696\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0558 - accuracy: 0.6706\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0561 - accuracy: 0.6687\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0574 - accuracy: 0.6689\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0552 - accuracy: 0.6671\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0530 - accuracy: 0.6700\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0516 - accuracy: 0.6680\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0476 - accuracy: 0.6693\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0546 - accuracy: 0.6675\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0500 - accuracy: 0.6675\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0480 - accuracy: 0.6680\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0508 - accuracy: 0.6671\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0508 - accuracy: 0.6669\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0401 - accuracy: 0.6689\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0491 - accuracy: 0.6659\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0516 - accuracy: 0.6659\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0407 - accuracy: 0.6683\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0430 - accuracy: 0.6650\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0356 - accuracy: 0.6675\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0390 - accuracy: 0.6668\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0317 - accuracy: 0.6724\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0454 - accuracy: 0.6706\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0292 - accuracy: 0.6720\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0220 - accuracy: 0.6700\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0285 - accuracy: 0.6718\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0274 - accuracy: 0.6708\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0244 - accuracy: 0.6708\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0221 - accuracy: 0.6726\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0219 - accuracy: 0.6721\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0131 - accuracy: 0.6730\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0159 - accuracy: 0.6745\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0128 - accuracy: 0.6745\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0199 - accuracy: 0.6738\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0071 - accuracy: 0.6747\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0121 - accuracy: 0.6745\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9864 - accuracy: 0.6750\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9601 - accuracy: 0.6750\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9467 - accuracy: 0.6768\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9271 - accuracy: 0.6794\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9153 - accuracy: 0.6803\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9081 - accuracy: 0.6814\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9083 - accuracy: 0.6788\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8947 - accuracy: 0.6815\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8985 - accuracy: 0.6806\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8838 - accuracy: 0.6839\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8810 - accuracy: 0.6839\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8821 - accuracy: 0.6869\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8665 - accuracy: 0.6899\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8640 - accuracy: 0.6867\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8807 - accuracy: 0.6855\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8584 - accuracy: 0.6972\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8515 - accuracy: 0.6949\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8475 - accuracy: 0.6975\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8424 - accuracy: 0.6954\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8372 - accuracy: 0.6979\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8258 - accuracy: 0.7031\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8342 - accuracy: 0.6981\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8069 - accuracy: 0.7045\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7992 - accuracy: 0.7119\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7963 - accuracy: 0.7048\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7852 - accuracy: 0.7095\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7813 - accuracy: 0.7188\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7763 - accuracy: 0.7118\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7845 - accuracy: 0.7142\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7743 - accuracy: 0.7183\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7553 - accuracy: 0.7274\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7569 - accuracy: 0.7267\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7482 - accuracy: 0.7250\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7507 - accuracy: 0.7225\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7474 - accuracy: 0.7243\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7345 - accuracy: 0.7270\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7278 - accuracy: 0.7328\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7320 - accuracy: 0.7301\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7283 - accuracy: 0.7352\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7250 - accuracy: 0.7349\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7167 - accuracy: 0.7374\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7103 - accuracy: 0.7392\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6964 - accuracy: 0.7437\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6978 - accuracy: 0.7475\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6764 - accuracy: 0.7560\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6673 - accuracy: 0.7571\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6621 - accuracy: 0.7599\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6437 - accuracy: 0.7638\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6475 - accuracy: 0.7665\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6423 - accuracy: 0.7659\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6536 - accuracy: 0.7650\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6150 - accuracy: 0.7744\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6122 - accuracy: 0.7751\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5949 - accuracy: 0.7770\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5846 - accuracy: 0.7852\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5780 - accuracy: 0.7838\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5679 - accuracy: 0.7921\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5374 - accuracy: 0.8054\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5241 - accuracy: 0.8100\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5175 - accuracy: 0.8070\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.5094 - accuracy: 0.8091\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4954 - accuracy: 0.8142\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.8204\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4724 - accuracy: 0.8277\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4682 - accuracy: 0.8259\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.8325\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.8331\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.8472\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3999 - accuracy: 0.8499\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3964 - accuracy: 0.8560\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3859 - accuracy: 0.8562\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3831 - accuracy: 0.8583\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3495 - accuracy: 0.8697\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3569 - accuracy: 0.8636\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3496 - accuracy: 0.8686\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3355 - accuracy: 0.8779\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3211 - accuracy: 0.8818\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3243 - accuracy: 0.8754\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3054 - accuracy: 0.8857\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2891 - accuracy: 0.8949\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.3052 - accuracy: 0.8858\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2901 - accuracy: 0.8943\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2751 - accuracy: 0.9006\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2367 - accuracy: 0.9134\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2721 - accuracy: 0.8951\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.2429 - accuracy: 0.9130\n",
      "104/104 - 0s - loss: 1.6128 - accuracy: 0.6850 - 384ms/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.6850227117538452 \n",
      "Test loss: 1.6128298044204712\n",
      "104/104 [==============================] - 0s 2ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6515249569046293\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 14.665840412243092 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 2.6914979674775203 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 2.6914979674775203\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 2.6914979674775203 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 37.97384857693099 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -18.064936679126227\n",
      "<__main__.particle object at 0x000002B16622A040> par x : 19.908911897804764 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : 19.908911897804764\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : 19.908911897804764 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 30.81140451400543 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -24.4850638084796\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 6.32634070552583 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 6.32634070552583\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 6.32634070552583 \n",
      "\n",
      "gbest: 2.6914979674775203\n",
      "epoch : 8\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 78, 58, 2)         56        \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 39, 29, 2)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 37, 27, 19)        361       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 18, 13, 19)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 11, 6)         1032      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 8, 5, 6)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 1687      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,136\n",
      "Trainable params: 3,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1457.5217 - accuracy: 0.4733\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 121.7849 - accuracy: 0.4946\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 1s 3ms/step - loss: 33.8025 - accuracy: 0.5010\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 7.8825 - accuracy: 0.5237\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 3.2706 - accuracy: 0.5490\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 2.5403 - accuracy: 0.5624\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 2.0297 - accuracy: 0.5824\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.6619 - accuracy: 0.6043\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.4250 - accuracy: 0.6304\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.2803 - accuracy: 0.6492\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1950 - accuracy: 0.6598\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1459 - accuracy: 0.6678\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1179 - accuracy: 0.6693\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0995 - accuracy: 0.6711\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0887 - accuracy: 0.6709\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0821 - accuracy: 0.6714\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0782 - accuracy: 0.6718\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0730 - accuracy: 0.6720\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0698 - accuracy: 0.6718\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0683 - accuracy: 0.6720\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0664 - accuracy: 0.6714\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0642 - accuracy: 0.6718\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0617 - accuracy: 0.6715\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0612 - accuracy: 0.6718\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0619 - accuracy: 0.6709\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0591 - accuracy: 0.6712\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0589 - accuracy: 0.6717\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0547 - accuracy: 0.6703\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0565 - accuracy: 0.6714\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0521 - accuracy: 0.6703\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0538 - accuracy: 0.6692\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0563 - accuracy: 0.6689\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0554 - accuracy: 0.6672\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0566 - accuracy: 0.6699\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0563 - accuracy: 0.6671\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0501 - accuracy: 0.6693\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0501 - accuracy: 0.6671\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0525 - accuracy: 0.6675\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0608 - accuracy: 0.6663\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0478 - accuracy: 0.6686\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0591 - accuracy: 0.6686\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0480 - accuracy: 0.6694\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0428 - accuracy: 0.6687\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0425 - accuracy: 0.6687\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0353 - accuracy: 0.6692\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0366 - accuracy: 0.6700\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0509 - accuracy: 0.6654\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0503 - accuracy: 0.6686\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0310 - accuracy: 0.6686\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0256 - accuracy: 0.6674\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0107 - accuracy: 0.6718\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0035 - accuracy: 0.6733\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9845 - accuracy: 0.6745\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9693 - accuracy: 0.6773\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9569 - accuracy: 0.6762\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9490 - accuracy: 0.6790\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9371 - accuracy: 0.6788\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9424 - accuracy: 0.6785\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9422 - accuracy: 0.6809\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9329 - accuracy: 0.6760\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9229 - accuracy: 0.6799\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9199 - accuracy: 0.6803\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9226 - accuracy: 0.6802\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9067 - accuracy: 0.6818\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9087 - accuracy: 0.6800\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9042 - accuracy: 0.6842\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9045 - accuracy: 0.6809\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.6844\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8948 - accuracy: 0.6841\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8816 - accuracy: 0.6852\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8782 - accuracy: 0.6887\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8717 - accuracy: 0.6905\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8772 - accuracy: 0.6890\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8695 - accuracy: 0.6920\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8721 - accuracy: 0.6927\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8655 - accuracy: 0.6921\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8613 - accuracy: 0.6943\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8502 - accuracy: 0.6964\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8492 - accuracy: 0.7012\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8482 - accuracy: 0.6936\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8243 - accuracy: 0.6978\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8227 - accuracy: 0.7045\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8065 - accuracy: 0.7080\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8077 - accuracy: 0.7048\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8013 - accuracy: 0.7095\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7844 - accuracy: 0.7113\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7849 - accuracy: 0.7164\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7795 - accuracy: 0.7189\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7753 - accuracy: 0.7174\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7669 - accuracy: 0.7228\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7511 - accuracy: 0.7268\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7518 - accuracy: 0.7271\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7415 - accuracy: 0.7353\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7392 - accuracy: 0.7316\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7368 - accuracy: 0.7313\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7316 - accuracy: 0.7332\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7149 - accuracy: 0.7355\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7149 - accuracy: 0.7385\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7030 - accuracy: 0.7407\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7043 - accuracy: 0.7416\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7092 - accuracy: 0.7425\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7413\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.7477\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6905 - accuracy: 0.7447\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7429\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6788 - accuracy: 0.7532\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6680 - accuracy: 0.7572\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6741 - accuracy: 0.7514\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6632 - accuracy: 0.7545\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6601 - accuracy: 0.7538\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6538 - accuracy: 0.7621\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6529 - accuracy: 0.7581\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6530 - accuracy: 0.7602\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6489 - accuracy: 0.7618\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6526 - accuracy: 0.7545\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6352 - accuracy: 0.7677\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6360 - accuracy: 0.7665\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6280 - accuracy: 0.7699\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6287 - accuracy: 0.7693\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6221 - accuracy: 0.7741\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6158 - accuracy: 0.7741\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6186 - accuracy: 0.7717\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6185 - accuracy: 0.7773\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6201 - accuracy: 0.7750\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6018 - accuracy: 0.7814\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5978 - accuracy: 0.7815\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6078 - accuracy: 0.7759\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5961 - accuracy: 0.7817\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6091 - accuracy: 0.7811\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5922 - accuracy: 0.7830\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.7876\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5932 - accuracy: 0.7864\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5845 - accuracy: 0.7872\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5740 - accuracy: 0.7870\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5838 - accuracy: 0.7848\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5697 - accuracy: 0.7928\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5652 - accuracy: 0.7945\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5691 - accuracy: 0.7925\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5626 - accuracy: 0.7939\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5606 - accuracy: 0.7958\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5595 - accuracy: 0.7902\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5657 - accuracy: 0.7960\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5608 - accuracy: 0.7937\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5471 - accuracy: 0.7970\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5454 - accuracy: 0.7975\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5498 - accuracy: 0.8012\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5565 - accuracy: 0.7909\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5503 - accuracy: 0.8015\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5353 - accuracy: 0.8031\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5472 - accuracy: 0.8040\n",
      "104/104 - 0s - loss: 0.9549 - accuracy: 0.6899 - 340ms/epoch - 3ms/step\n",
      "\n",
      "Test accuracy: 0.6898638606071472 \n",
      "Test loss: 0.9548980593681335\n",
      "104/104 [==============================] - 0s 1ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6764700495168353\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 2.6914979674775203 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : -11.974342444765572\n",
      "<__main__.particle object at 0x000002B178990E20> par x : -9.282844477288052 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 2.6914979674775203\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : -9.282844477288052 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : 19.908911897804764 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -25.379387983393123\n",
      "<__main__.particle object at 0x000002B16622A040> par x : -5.470476085588359 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : -5.470476085588359\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : -5.470476085588359 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 6.32634070552583 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : -25.04374838030515\n",
      "<__main__.particle object at 0x000002B16622A730> par x : -18.71740767477932 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 6.32634070552583\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : -18.71740767477932 \n",
      "\n",
      "gbest: 2.6914979674775203\n",
      "epoch : 9\n",
      "Model: \"sequential_8\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 78, 58, 9)         252       \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 39, 29, 9)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 37, 27, 5)         410       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 18, 13, 5)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 16, 11, 18)        828       \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 8, 5, 18)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 720)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 5047      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,537\n",
      "Trainable params: 6,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1248.8656 - accuracy: 0.5009\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 41.8639 - accuracy: 0.5158\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 6.0107 - accuracy: 0.5382\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.6608 - accuracy: 0.6063\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.4053 - accuracy: 0.6308\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.2574 - accuracy: 0.6463\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1765 - accuracy: 0.6598\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1286 - accuracy: 0.6651\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1039 - accuracy: 0.6684\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0899 - accuracy: 0.6697\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0808 - accuracy: 0.6706\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0764 - accuracy: 0.6717\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0715 - accuracy: 0.6724\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0680 - accuracy: 0.6723\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0645 - accuracy: 0.6718\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0638 - accuracy: 0.6720\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0619 - accuracy: 0.6718\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0609 - accuracy: 0.6723\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0573 - accuracy: 0.6721\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0557 - accuracy: 0.6717\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0556 - accuracy: 0.6721\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0556 - accuracy: 0.6720\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0563 - accuracy: 0.6714\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0529 - accuracy: 0.6711\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0519 - accuracy: 0.6706\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0517 - accuracy: 0.6703\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0581 - accuracy: 0.6705\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0548 - accuracy: 0.6696\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0531 - accuracy: 0.6697\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0550 - accuracy: 0.6694\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0456 - accuracy: 0.6705\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0484 - accuracy: 0.6687\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0466 - accuracy: 0.6696\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0469 - accuracy: 0.6681\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0519 - accuracy: 0.6641\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0472 - accuracy: 0.6665\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0438 - accuracy: 0.6668\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0501 - accuracy: 0.6660\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0476 - accuracy: 0.6638\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0521 - accuracy: 0.6666\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0461 - accuracy: 0.6654\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0409 - accuracy: 0.6684\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0398 - accuracy: 0.6677\n",
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0221 - accuracy: 0.6732\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0265 - accuracy: 0.6697\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0137 - accuracy: 0.6721\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9914 - accuracy: 0.6702\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9867 - accuracy: 0.6726\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9892 - accuracy: 0.6709\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9708 - accuracy: 0.6756\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9682 - accuracy: 0.6762\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9607 - accuracy: 0.6782\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9481 - accuracy: 0.6784\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9362 - accuracy: 0.6791\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9275 - accuracy: 0.6818\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9339 - accuracy: 0.6817\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9171 - accuracy: 0.6805\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9134 - accuracy: 0.6802\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9060 - accuracy: 0.6849\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8947 - accuracy: 0.6851\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8921 - accuracy: 0.6844\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8957 - accuracy: 0.6830\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9012 - accuracy: 0.6833\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8802 - accuracy: 0.6876\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8764 - accuracy: 0.6885\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8759 - accuracy: 0.6852\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8768 - accuracy: 0.6884\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8736 - accuracy: 0.6888\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8597 - accuracy: 0.6918\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8605 - accuracy: 0.6900\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8520 - accuracy: 0.6918\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8562 - accuracy: 0.6918\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8382 - accuracy: 0.6942\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8531 - accuracy: 0.6931\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8420 - accuracy: 0.6991\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8387 - accuracy: 0.6958\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8247 - accuracy: 0.7000\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8268 - accuracy: 0.7019\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8191 - accuracy: 0.7018\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8090 - accuracy: 0.7048\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8040 - accuracy: 0.7066\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8032 - accuracy: 0.7092\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.8076 - accuracy: 0.7079\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7854 - accuracy: 0.7143\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7814 - accuracy: 0.7131\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7755 - accuracy: 0.7164\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7707 - accuracy: 0.7195\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7751 - accuracy: 0.7167\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7780 - accuracy: 0.7174\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7499 - accuracy: 0.7247\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7413 - accuracy: 0.7276\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7438 - accuracy: 0.7298\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7262 - accuracy: 0.7328\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7189 - accuracy: 0.7362\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7018 - accuracy: 0.7410\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7026 - accuracy: 0.7401\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7008 - accuracy: 0.7431\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6857 - accuracy: 0.7513\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7528\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6723 - accuracy: 0.7489\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6680 - accuracy: 0.7548\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6550 - accuracy: 0.7593\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6454 - accuracy: 0.7653\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6470 - accuracy: 0.7575\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6354 - accuracy: 0.7669\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6285 - accuracy: 0.7714\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6282 - accuracy: 0.7644\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6144 - accuracy: 0.7730\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6050 - accuracy: 0.7769\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6036 - accuracy: 0.7766\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5842 - accuracy: 0.7836\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5806 - accuracy: 0.7809\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5841 - accuracy: 0.7794\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5627 - accuracy: 0.7903\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5574 - accuracy: 0.7928\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5592 - accuracy: 0.7924\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5581 - accuracy: 0.7872\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5417 - accuracy: 0.7917\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5275 - accuracy: 0.8028\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5241 - accuracy: 0.8042\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.5254 - accuracy: 0.8058\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 458s 2s/step - loss: 0.5215 - accuracy: 0.8070\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.5120 - accuracy: 0.8089\n",
      "Epoch 124/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4988 - accuracy: 0.8133\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4944 - accuracy: 0.8145\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4951 - accuracy: 0.8146\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4845 - accuracy: 0.8262\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4761 - accuracy: 0.8194\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4667 - accuracy: 0.8262\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.8268\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.8298\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4552 - accuracy: 0.8306\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4539 - accuracy: 0.8304\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4430 - accuracy: 0.8334\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.8382\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4410 - accuracy: 0.8334\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4367 - accuracy: 0.8338\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4383 - accuracy: 0.8343\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4487 - accuracy: 0.8310\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.8389\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4167 - accuracy: 0.8425\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4124 - accuracy: 0.8469\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.8507\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8487\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4099 - accuracy: 0.8499\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4186 - accuracy: 0.8441\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 2s 9ms/step - loss: 0.4119 - accuracy: 0.8426\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 0.3959 - accuracy: 0.8548\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8468\n",
      "104/104 - 1s - loss: 1.2251 - accuracy: 0.6593 - 571ms/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.6593040823936462 \n",
      "Test loss: 1.2251322269439697\n",
      "104/104 [==============================] - 0s 2ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6518114026167108\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : -9.282844477288052 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : 16.863199121836416\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 7.580354644548365 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 2.6914979674775203\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 7.580354644548365 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : -5.470476085588359 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : -22.454804660602573\n",
      "<__main__.particle object at 0x000002B16622A040> par x : -27.925280746190932 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : -5.470476085588359\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : -27.925280746190932 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : -18.71740767477932 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : 22.642210250354058\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 3.9248025755747378 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 3.9248025755747378\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 3.9248025755747378 \n",
      "\n",
      "gbest: 2.6914979674775203\n",
      "epoch : 10\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 78, 58, 7)         196       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 39, 29, 7)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 37, 27, 27)        1728      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 18, 13, 27)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 16, 11, 3)         732       \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 8, 5, 3)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 847       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,503\n",
      "Trainable params: 3,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 10040.1074 - accuracy: 0.4557\n",
      "Epoch 2/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 910.4862 - accuracy: 0.4785\n",
      "Epoch 3/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 379.1951 - accuracy: 0.4912\n",
      "Epoch 4/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 175.9924 - accuracy: 0.4943\n",
      "Epoch 5/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 81.4331 - accuracy: 0.4976\n",
      "Epoch 6/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 33.9486 - accuracy: 0.5040\n",
      "Epoch 7/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 13.7014 - accuracy: 0.5174\n",
      "Epoch 8/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 10.5841 - accuracy: 0.5176\n",
      "Epoch 9/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 8.9498 - accuracy: 0.5252\n",
      "Epoch 10/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 7.5571 - accuracy: 0.5261\n",
      "Epoch 11/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 6.2363 - accuracy: 0.5292\n",
      "Epoch 12/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 5.1125 - accuracy: 0.5353\n",
      "Epoch 13/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 4.1452 - accuracy: 0.5444\n",
      "Epoch 14/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 3.3534 - accuracy: 0.5498\n",
      "Epoch 15/150\n",
      "210/210 [==============================] - 2s 7ms/step - loss: 2.7215 - accuracy: 0.5611\n",
      "Epoch 16/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 2.2344 - accuracy: 0.5775\n",
      "Epoch 17/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.8611 - accuracy: 0.5934\n",
      "Epoch 18/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.5964 - accuracy: 0.6119\n",
      "Epoch 19/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.4111 - accuracy: 0.6261\n",
      "Epoch 20/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.2848 - accuracy: 0.6392\n",
      "Epoch 21/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.2029 - accuracy: 0.6487\n",
      "Epoch 22/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1510 - accuracy: 0.6560\n",
      "Epoch 23/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.1190 - accuracy: 0.6623\n",
      "Epoch 24/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0991 - accuracy: 0.6665\n",
      "Epoch 25/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0867 - accuracy: 0.6684\n",
      "Epoch 26/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0784 - accuracy: 0.6699\n",
      "Epoch 27/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0731 - accuracy: 0.6699\n",
      "Epoch 28/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0689 - accuracy: 0.6708\n",
      "Epoch 29/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0653 - accuracy: 0.6708\n",
      "Epoch 30/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0631 - accuracy: 0.6708\n",
      "Epoch 31/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0613 - accuracy: 0.6709\n",
      "Epoch 32/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0601 - accuracy: 0.6709\n",
      "Epoch 33/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0581 - accuracy: 0.6711\n",
      "Epoch 34/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0592 - accuracy: 0.6711\n",
      "Epoch 35/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0570 - accuracy: 0.6706\n",
      "Epoch 36/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0565 - accuracy: 0.6712\n",
      "Epoch 37/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0555 - accuracy: 0.6706\n",
      "Epoch 38/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0549 - accuracy: 0.6706\n",
      "Epoch 39/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0539 - accuracy: 0.6711\n",
      "Epoch 40/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0540 - accuracy: 0.6709\n",
      "Epoch 41/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0506 - accuracy: 0.6703\n",
      "Epoch 42/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0536 - accuracy: 0.6692\n",
      "Epoch 43/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0500 - accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0506 - accuracy: 0.6712\n",
      "Epoch 45/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0509 - accuracy: 0.6700\n",
      "Epoch 46/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0538 - accuracy: 0.6690\n",
      "Epoch 47/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0516 - accuracy: 0.6703\n",
      "Epoch 48/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0574 - accuracy: 0.6678\n",
      "Epoch 49/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0514 - accuracy: 0.6694\n",
      "Epoch 50/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0539 - accuracy: 0.6669\n",
      "Epoch 51/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0447 - accuracy: 0.6705\n",
      "Epoch 52/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0456 - accuracy: 0.6686\n",
      "Epoch 53/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0482 - accuracy: 0.6681\n",
      "Epoch 54/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0474 - accuracy: 0.6683\n",
      "Epoch 55/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0502 - accuracy: 0.6684\n",
      "Epoch 56/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0551 - accuracy: 0.6656\n",
      "Epoch 57/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0538 - accuracy: 0.6665\n",
      "Epoch 58/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0582 - accuracy: 0.6666\n",
      "Epoch 59/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0454 - accuracy: 0.6702\n",
      "Epoch 60/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0528 - accuracy: 0.6669\n",
      "Epoch 61/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0476 - accuracy: 0.6693\n",
      "Epoch 62/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 1.0604 - accuracy: 0.6686\n",
      "Epoch 63/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0407 - accuracy: 0.6683\n",
      "Epoch 64/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0467 - accuracy: 0.6617\n",
      "Epoch 65/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0306 - accuracy: 0.6694\n",
      "Epoch 66/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 1.0409 - accuracy: 0.6668\n",
      "Epoch 67/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0154 - accuracy: 0.6666\n",
      "Epoch 68/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 1.0144 - accuracy: 0.6693\n",
      "Epoch 69/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9965 - accuracy: 0.6718\n",
      "Epoch 70/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9919 - accuracy: 0.6696\n",
      "Epoch 71/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9801 - accuracy: 0.6706\n",
      "Epoch 72/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.9729 - accuracy: 0.6733\n",
      "Epoch 73/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9665 - accuracy: 0.6690\n",
      "Epoch 74/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9489 - accuracy: 0.6762\n",
      "Epoch 75/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9596 - accuracy: 0.6730\n",
      "Epoch 76/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.9519 - accuracy: 0.6720\n",
      "Epoch 77/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9206 - accuracy: 0.6763\n",
      "Epoch 78/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9309 - accuracy: 0.6747\n",
      "Epoch 79/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9388 - accuracy: 0.6772\n",
      "Epoch 80/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9198 - accuracy: 0.6768\n",
      "Epoch 81/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.9220 - accuracy: 0.6748\n",
      "Epoch 82/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9070 - accuracy: 0.6811\n",
      "Epoch 83/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9006 - accuracy: 0.6844\n",
      "Epoch 84/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9075 - accuracy: 0.6796\n",
      "Epoch 85/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.9024 - accuracy: 0.6821\n",
      "Epoch 86/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8956 - accuracy: 0.6823\n",
      "Epoch 87/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8994 - accuracy: 0.6791\n",
      "Epoch 88/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8927 - accuracy: 0.6849\n",
      "Epoch 89/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8925 - accuracy: 0.6833\n",
      "Epoch 90/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8941 - accuracy: 0.6849\n",
      "Epoch 91/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.8800 - accuracy: 0.6867\n",
      "Epoch 92/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8757 - accuracy: 0.6891\n",
      "Epoch 93/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8754 - accuracy: 0.6873\n",
      "Epoch 94/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8717 - accuracy: 0.6908\n",
      "Epoch 95/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8668 - accuracy: 0.6931\n",
      "Epoch 96/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8614 - accuracy: 0.6911\n",
      "Epoch 97/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8528 - accuracy: 0.6954\n",
      "Epoch 98/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8424 - accuracy: 0.6931\n",
      "Epoch 99/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8469 - accuracy: 0.6940\n",
      "Epoch 100/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8342 - accuracy: 0.6915\n",
      "Epoch 101/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.8241 - accuracy: 0.6967\n",
      "Epoch 102/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8180 - accuracy: 0.7024\n",
      "Epoch 103/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8181 - accuracy: 0.6985\n",
      "Epoch 104/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8051 - accuracy: 0.7045\n",
      "Epoch 105/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.8116 - accuracy: 0.7051\n",
      "Epoch 106/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.7978 - accuracy: 0.7069\n",
      "Epoch 107/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.8148 - accuracy: 0.7025\n",
      "Epoch 108/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7986 - accuracy: 0.7054\n",
      "Epoch 109/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7911 - accuracy: 0.7091\n",
      "Epoch 110/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7831 - accuracy: 0.7143\n",
      "Epoch 111/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.7822 - accuracy: 0.7106\n",
      "Epoch 112/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7688 - accuracy: 0.7167\n",
      "Epoch 113/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7719 - accuracy: 0.7124\n",
      "Epoch 114/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7642 - accuracy: 0.7222\n",
      "Epoch 115/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.7696 - accuracy: 0.7174\n",
      "Epoch 116/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7625 - accuracy: 0.7176\n",
      "Epoch 117/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7696 - accuracy: 0.7133\n",
      "Epoch 118/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7527 - accuracy: 0.7250\n",
      "Epoch 119/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7500 - accuracy: 0.7207\n",
      "Epoch 120/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7614 - accuracy: 0.7197\n",
      "Epoch 121/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7419 - accuracy: 0.7258\n",
      "Epoch 122/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7453 - accuracy: 0.7216\n",
      "Epoch 123/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7273 - accuracy: 0.7301\n",
      "Epoch 124/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7328 - accuracy: 0.7298\n",
      "Epoch 125/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.7282 - accuracy: 0.7271\n",
      "Epoch 126/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7145 - accuracy: 0.7337\n",
      "Epoch 127/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7148 - accuracy: 0.7350\n",
      "Epoch 128/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7224 - accuracy: 0.7314\n",
      "Epoch 129/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7110 - accuracy: 0.7359\n",
      "Epoch 130/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.7057 - accuracy: 0.7385\n",
      "Epoch 131/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7056 - accuracy: 0.7392\n",
      "Epoch 132/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6926 - accuracy: 0.7441\n",
      "Epoch 133/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.7011 - accuracy: 0.7402\n",
      "Epoch 134/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6990 - accuracy: 0.7379\n",
      "Epoch 135/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.7458\n",
      "Epoch 136/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6869 - accuracy: 0.7477\n",
      "Epoch 137/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6863 - accuracy: 0.7423\n",
      "Epoch 138/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6870 - accuracy: 0.7471\n",
      "Epoch 139/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6721 - accuracy: 0.7513\n",
      "Epoch 140/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.6700 - accuracy: 0.7513\n",
      "Epoch 141/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6683 - accuracy: 0.7544\n",
      "Epoch 142/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6648 - accuracy: 0.7519\n",
      "Epoch 143/150\n",
      "210/210 [==============================] - 1s 7ms/step - loss: 0.6672 - accuracy: 0.7531\n",
      "Epoch 144/150\n",
      "210/210 [==============================] - 1s 6ms/step - loss: 0.6675 - accuracy: 0.7538\n",
      "Epoch 145/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6577 - accuracy: 0.7545\n",
      "Epoch 146/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6642 - accuracy: 0.7508\n",
      "Epoch 147/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6603 - accuracy: 0.7547\n",
      "Epoch 148/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6525 - accuracy: 0.7572\n",
      "Epoch 149/150\n",
      "210/210 [==============================] - 1s 4ms/step - loss: 0.6505 - accuracy: 0.7575\n",
      "Epoch 150/150\n",
      "210/210 [==============================] - 1s 5ms/step - loss: 0.6613 - accuracy: 0.7551\n",
      "104/104 - 1s - loss: 0.9474 - accuracy: 0.6874 - 560ms/epoch - 5ms/step\n",
      "\n",
      "Test accuracy: 0.6874432563781738 \n",
      "Test loss: 0.9474258422851562\n",
      "104/104 [==============================] - 0s 3ms/step\n",
      "AÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ F1 Sokru: 0.6456353043114323\n",
      "--old par <__main__.particle object at 0x000002B178990E20> x : 7.580354644548365 \n",
      "<__main__.particle object at 0x000002B178990E20> par deÄŸiÅŸim hÄ±zÄ± : 8.282577363537131\n",
      "<__main__.particle object at 0x000002B178990E20> par x : 15.862932008085496 \n",
      "<__main__.particle object at 0x000002B178990E20> par pbest : 2.6914979674775203\n",
      "--new par <__main__.particle object at 0x000002B178990E20> x : 15.862932008085496 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A040> x : -27.925280746190932 \n",
      "<__main__.particle object at 0x000002B16622A040> par deÄŸiÅŸim hÄ±zÄ± : 26.556829554126622\n",
      "<__main__.particle object at 0x000002B16622A040> par x : -1.3684511920643097 \n",
      "<__main__.particle object at 0x000002B16622A040> par pbest : -1.3684511920643097\n",
      "--new par <__main__.particle object at 0x000002B16622A040> x : -1.3684511920643097 \n",
      "\n",
      "--old par <__main__.particle object at 0x000002B16622A730> x : 3.9248025755747378 \n",
      "<__main__.particle object at 0x000002B16622A730> par deÄŸiÅŸim hÄ±zÄ± : 22.40411015399739\n",
      "<__main__.particle object at 0x000002B16622A730> par x : 26.328912729572128 \n",
      "<__main__.particle object at 0x000002B16622A730> par pbest : 3.9248025755747378\n",
      "--new par <__main__.particle object at 0x000002B16622A730> x : 26.328912729572128 \n",
      "\n",
      "index:0 15.862932008085496\n",
      "index:1 -1.3684511920643097\n",
      "index:2 26.328912729572128\n"
     ]
    }
   ],
   "source": [
    "particles = Particles()\n",
    "particles.define_particles([72,56,64])\n",
    "particles.find_gbest()\n",
    "particles.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f3a2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(excel_file_path, mode='w') as writer:\n",
    "    res_df = pd.DataFrame(data)\n",
    "    res_df.to_excel(writer, index=False, header=False, sheet_name=\"sheet4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37939d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73988ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594452a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609dc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56919c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
